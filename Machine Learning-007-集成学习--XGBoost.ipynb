{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 共分成5步：\n",
    "1, 加载数据；\n",
    "2，实例化xgb分类器对象，并训练模型；\n",
    "3，预测；\n",
    "4，网格调参；\n",
    "5，XGBoost的核心思想。'''\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1, 加载数据：\n",
    "myDatas = datasets.load_iris()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(  #划分训练集、测试集\n",
    "    myDatas.data,myDatas.target,   #load_iris的原始数据集\n",
    "    test_size = 0.3,\n",
    "    random_state = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2，实例化xgb分类器对象，并训练模型：\n",
    "clfXgb = XGBClassifier(n_estimators=10,max_depth=3,learning_rate=0.1)  #learning_rate = 0.1 根据经验是最合适的学习率，精确度0.93，改成0.5，精确度降为0.91了。\n",
    "# 若将xgb用于回归，与分类类似，只需实例化模型：rXgb = XGBRegressor(n_estimators=10,max_depth=3)\n",
    "clfXgb.fit(X_train,y_train)   #训练分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测精确度： 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 3，预测\n",
    "clfXgbPred = clfXgb.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,clfXgbPred)   #评估得分\n",
    "\n",
    "print(\"预测精确度：\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优学习率: {'learning_rate': 0.1} ，得分：-0.169467 \n",
      "每次迭代的平均值： [-1.08640095 -0.98505858 -0.169467   -0.18732891 -0.18775922]\n",
      "对应的本次迭代学习率参数： [{'learning_rate': 0.0001}, {'learning_rate': 0.001}, {'learning_rate': 0.1}, {'learning_rate': 0.2}, {'learning_rate': 0.3}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#以上调参完即可确定最优的learning_rate在模型中使用了，代回去再次建模，\\n#才可得到开篇中的最精确的预测值。\\n#试下把开篇learning_rate = 0.1 改成0.5，精确度从0.93降为0.91了。\\n#此模型才可用于其它同类任务的预测工作，总的流程是这样的。\\n#此处只调了一个参数举例，其它参数必要时也要调\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4，网格调参：\n",
    "#模型建好以后要选一些合适的参数，让模型最优（损失最小）才是目的，\n",
    "#然后把这些参数应用到模型，重新建模保存，服务于更多任务的测试工作==\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "myMode = XGBClassifier()#正常这里是不会人为揸定参数，要求最合适参数，上面实例只是根据经验传了固定参数展示分类实现，\n",
    "#以学习率为例，找一个最合适的学习率\n",
    "#设几个不同学习率的列表，后面来遍历它，看哪个学习率下分类精确度最高，就用哪个学习率代回模型重新建模\n",
    "learning_rate=[0.0001,0.001,0.1,0.2,0.3]\n",
    "#这次使用交叉验证（交替充份使用有限数据）划分数据集\n",
    "#实例化交叉验证类\n",
    "kfold = StratifiedKFold(n_splits=2,shuffle=True,random_state=7)\n",
    "#n_splits分成几组测试验证对\n",
    "#实例化网格调参类（传入交叉验实例对象及XGB分类对象）\n",
    "grid_search = GridSearchCV(myMode,#传入XGB分类对象\n",
    "                           dict(learning_rate=learning_rate),#这里要字典格式打包传参\n",
    "                           scoring = 'neg_log_loss',#评估损失函数选择\n",
    "                           n_jobs = 1,#当前所有空闲CPU都去跑这个模型\n",
    "                           cv = kfold#指定交叉验证实例对象\n",
    "                          )\n",
    "#用最终结合好的对象fit原始数据即可自动完成交叉验证并调参\n",
    "gridRs = grid_search.fit(myDatas.data,myDatas.target)\n",
    "\n",
    "#打印最优学习率和其得分\n",
    "print(\"最优学习率: %s ，得分：%f \" % (gridRs.best_params_,gridRs.best_score_))\n",
    "means = gridRs.cv_results_['mean_test_score']\n",
    "params = gridRs.cv_results_['params']\n",
    "#打印平均分\n",
    "print(\"每次迭代的平均值：\",means)\n",
    "print(\"对应的本次迭代学习率参数：\",params)\n",
    "\n",
    "'''\n",
    "#以上调参完即可确定最优的learning_rate在模型中使用了，代回去再次建模，\n",
    "#才可得到开篇中的最精确的预测值。\n",
    "#试下把开篇learning_rate = 0.1 改成0.5，精确度从0.93降为0.91了。\n",
    "#此模型才可用于其它同类任务的预测工作，总的流程是这样的。\n",
    "#此处只调了一个参数举例，其它参数必要时也要调\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.98021\n",
      "Will train until validation_0-mlogloss hasn't improved in 3 rounds.\n",
      "[1]\tvalidation_0-mlogloss:0.881483\n",
      "[2]\tvalidation_0-mlogloss:0.798046\n",
      "[3]\tvalidation_0-mlogloss:0.72683\n",
      "[4]\tvalidation_0-mlogloss:0.665589\n",
      "[5]\tvalidation_0-mlogloss:0.612621\n",
      "[6]\tvalidation_0-mlogloss:0.566605\n",
      "[7]\tvalidation_0-mlogloss:0.52649\n",
      "[8]\tvalidation_0-mlogloss:0.491428\n",
      "[9]\tvalidation_0-mlogloss:0.460721\n",
      "\n",
      "预测精确度: 0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5，XGBoost的核心思想\n",
    "# 下面通过每一步的test预测值，看是否XGBoost每加一棵树都会让集成学习效果优化提升(这是XGBoost的核心思想)。\n",
    "eval_set = [(X_test,y_test)]   # 构造一个测试集\n",
    "\n",
    "clfXgb.fit(X_train,y_train,early_stopping_rounds=3,\n",
    "           eval_metric='mlogloss',eval_set = eval_set,verbose = True)\n",
    "#参数：模型饱和后再加3次停止该模型\n",
    "#指定mlogloss为损失函数，用来做模型优化标准，使logloss最小。\n",
    "#测试值\n",
    "clfXgbPred_2 = clfXgb.predict(X_test)\n",
    "#把预测值装进预测值列表\n",
    "predictions = [round(v) for v in clfXgbPred_2]\n",
    "#遍历预测结果评估\n",
    "acc_2 = accuracy_score(y_test,predictions)#每个测试结果和它对应的所有预测值比较分别评估\n",
    "\n",
    "print(\"\\n预测精确度:\",acc_2)\n",
    "#由结果可见XGB的确是在每步加入新村时使得集成学习向优化提升（损失越来越小，预测越来越接近真实值）\n",
    "#另外上面设了early_stopping_rounds 为3 说明从底下往上数3个0.56时模型就已经是饱和状态了。\n",
    "\n",
    "\n",
    "#==下面看一个xgboost的功能\n",
    "#plot_importantce，\n",
    "#可以查看特征重要性==\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "model = XGBClassifier()   #实例化分类器对象\n",
    "model.fit(myDatas.data,myDatas.target)   #对象fit传原始数据集即可\n",
    "rs = plot_importance(model)   #算特征重要性\n",
    "pyplot.show(rs)   # 可视化\n",
    "#图上列出了4个特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
